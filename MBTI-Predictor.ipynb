{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Neural Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 673\n",
    "# 1st Layer\n",
    "LAYER1_SIZE = 16\n",
    "LAYER1_ACTIVATION = 'relu'\n",
    "LAYER1_INPUT_DIMENSION = 10000\n",
    "\n",
    "LAYER1_PARAMS = [str(LAYER1_SIZE), LAYER1_ACTIVATION, LAYER1_INPUT_DIMENSION]\n",
    "\n",
    "# 2nd LAYER\n",
    "LAYER2_SIZE = 16\n",
    "LAYER2_ACTIVATION = 'relu'\n",
    "\n",
    "LAYER2_PARAMS = [str(LAYER2_SIZE), LAYER2_ACTIVATION]\n",
    "\n",
    "# 3rd LAYER\n",
    "LAYER3_SIZE = 4\n",
    "LAYER3_ACTIVATION = 'sigmoid'\n",
    "\n",
    "LAYER3_PARAMS = [str(LAYER3_SIZE), LAYER3_ACTIVATION]\n",
    "\n",
    "# Geralizers\n",
    "DROPOUT_RATE = 0.5\n",
    "L1 = 0.001\n",
    "L2 = 0.001\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "TRAIN_PARAMS = [EPOCHS, BATCH_SIZE]\n",
    "\n",
    "# COMPILATION\n",
    "OPTIMIZER = 'rmsprop'\n",
    "LOSS = 'binary_crossentropy'\n",
    "METRICS = 'accuracy'\n",
    "\n",
    "COMPILATION_PARAMS = [OPTIMIZER, LOSS, METRICS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over Sampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains 8600ish users Data\n",
    "# In the form: {'MBTI Type', 'Social Media Posts'}\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "data = pd.read_csv('mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1441516f438>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_distribution = data.groupby(\"type\").count().sort_values(\"posts\", ascending=False)\n",
    "type_distribution[\"posts\"].plot(kind=\"bar\", title=\"Number of Users per Personality type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, The data is very much inbalanced. By my calculations about 76% Introver to Extrovert. Our original models were statistically invalid, as overfitting happen basically instantaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8675"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "tokenized_posts = []\n",
    "with open ('tokenized_formatted_data.txt', 'rb') as fp:\n",
    "    tokenized_posts = pickle.load(fp)\n",
    "    \n",
    "types = data.type\n",
    "posts = data.posts\n",
    "l"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Turning the posts from: 'post1|||post2|||post3'\n",
    "#                     to: ['post1', 'post2', 'post3']\n",
    "# expects a list of posts as strings\n",
    "# returns a list of lists of posts\n",
    "def vectorize_post_data(posts):\n",
    "    for index in range(0, len(posts)):\n",
    "        posts[index] = posts[index].split(\"|||\")\n",
    "        \n",
    "    return posts\n",
    "\n",
    "posts = vectorize_post_data(posts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def remove_hyperTextLinksFromPosts(posts):\n",
    "    for index in range(0, len(posts)):\n",
    "        usable_post = [post for post in posts[index] if not re.search(r'^(.)*http(.)*$', post)]\n",
    "        posts[index] = usable_post\n",
    "    \n",
    "    return posts\n",
    "        \n",
    "posts = remove_hyperTextLinksFromPosts(posts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def remove_MBTIClassifiersFromPosts(posts):\n",
    "    MBTI_regex = r'[\\w]*(i|e)(s|n)(f|t)(p|j)[\\w]*'\n",
    "    for i in range(0, len(posts)):\n",
    "        for j in range(0, len(posts[i])):\n",
    "            posts[i][j] = re.sub(MBTI_regex, ' ', posts[i][j], flags=re.IGNORECASE)\n",
    "        \n",
    "    return posts\n",
    "    \n",
    "posts = remove_MBTIClassifiersFromPosts(posts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def isInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def tokenize_posts(posts):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    for i in range(0, len(posts)):\n",
    "        user_words = []\n",
    "        for j in range(0, len(posts[i])):\n",
    "            post = tokenizer.tokenize(posts[i][j])\n",
    "            for word in post:\n",
    "                if not isInt(word) and len(word) > 1:\n",
    "                    user_words.append(word.lower())\n",
    "                user_words = [w for w in user_words if not w in stop_words]\n",
    "        posts[i] = user_words\n",
    "    \n",
    "    return posts\n",
    "\n",
    "posts = tokenize_posts(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tokenized_posts = []\n",
    "with open ('tokenized_formatted_data.txt', 'rb') as fp:\n",
    "    tokenized_posts = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_list = []\n",
    "\n",
    "for user in tokenized_posts:\n",
    "    for word in user:\n",
    "        all_words_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_list = Counter(all_words_list)\n",
    "dictionary = freq_list.most_common(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = list(zip(*dictionary))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = range(0, 10000)\n",
    "word_int = dict(zip(dictionary, nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = []\n",
    "\n",
    "for user in tokenized_posts:\n",
    "    x_vals.append([word_int[x] for x in user if x in word_int.keys()])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "intr_extr = [word[0:1] for word in types]\n",
    "\n",
    "for letter in intr_extr:\n",
    "    if (letter == 'I'):\n",
    "        bin_intro_extro.append(0)\n",
    "    else:\n",
    "        bin_intro_extro.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dictionary = {\n",
    "    '0000':'INTJ',\n",
    "    '0001':'INTP',\n",
    "    '0010':'INFJ',\n",
    "    '0011':'INFP',\n",
    "    '0100':'ISTJ',\n",
    "    '0101':'ISTP',\n",
    "    '0110':'ISFJ',\n",
    "    '0111':'ISFP',\n",
    "    '1000':'ENTJ',\n",
    "    '1001':'ENTP',\n",
    "    '1010':'ENFJ',\n",
    "    '1011':'ENFP',\n",
    "    '1100':'ESTJ',\n",
    "    '1101':'ESTP',\n",
    "    '1110':'ESFJ',\n",
    "    '1111':'ESFP',\n",
    "}\n",
    "\n",
    "type_labels=['INTJ','INTP','INFJ','INFP','ISTJ','ISTP','ISFJ','ISFP', \\\n",
    "        'ENTJ','ENTP','ENFJ','ENFP','ESTJ','ESTP','ESFJ','ESFP',]\n",
    "\n",
    "one_hot_types = []\n",
    "for type in types:\n",
    "    bin_type = []\n",
    "    if (type[0] == 'I'):\n",
    "        bin_type.append(0)\n",
    "    else:\n",
    "        bin_type.append(1)\n",
    "        \n",
    "    if (type[1] == 'N'):\n",
    "        bin_type.append(0)\n",
    "    else:\n",
    "        bin_type.append(1)\n",
    "        \n",
    "    if (type[2] == 'T'):\n",
    "        bin_type.append(0)\n",
    "    else:\n",
    "        bin_type.append(1)\n",
    "    \n",
    "    if (type[3] == 'J'):\n",
    "        bin_type.append(0)\n",
    "    else:\n",
    "        bin_type.append(1)\n",
    "    one_hot_types.append(bin_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "x = np.array(x_vals)\n",
    "random.seed(SEED)\n",
    "random.shuffle(x)\n",
    "test_data = x[:1500]\n",
    "train_data = x[1500:]\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y = np.asarray(one_hot_types).astype('float32')\n",
    "random.seed(SEED)\n",
    "random.shuffle(y)\n",
    "y_test = y[:1500]\n",
    "y_train = y[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1500]\n",
    "x_partial_train = x_train[1500:]\n",
    "\n",
    "y_val = y_train[:1500]\n",
    "y_partial_train = y_train[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEED FORWARD MODEL\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "#kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(LAYER1_SIZE, activation=LAYER1_ACTIVATION, input_shape = (LAYER1_INPUT_DIMENSION,)))\n",
    "    model.add(layers.Dense(LAYER2_SIZE, activation=LAYER2_ACTIVATION))\n",
    "    model.add(layers.Dense(LAYER3_SIZE, activation=LAYER3_ACTIVATION))\n",
    "    model.compile(optimizer = OPTIMIZER, loss = LOSS, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7175/7175 [==============================] - 3s 384us/step - loss: 0.5835 - acc: 0.6876\n",
      "Epoch 2/3\n",
      "7175/7175 [==============================] - 1s 128us/step - loss: 0.5316 - acc: 0.7433\n",
      "Epoch 3/3\n",
      "7175/7175 [==============================] - 1s 124us/step - loss: 0.4881 - acc: 0.7748\n",
      "1500/1500 [==============================] - 0s 170us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6218339424133301, 0.6828333330154419]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(x_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE)\n",
    "    y_pred = model.predict(x_test)\n",
    "    results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "counter = 0\n",
    "for label in types:\n",
    "    if label == 'INFP':\n",
    "        counter +=1\n",
    "counter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def byte_to_mbti(byte):\n",
    "    binary = ''\n",
    "    for letter in byte:\n",
    "         binary +=(str(int(letter)))        \n",
    "    return type_dictionary[binary]\n",
    "\n",
    "decoded_y_true = [byte_to_mbti(label) for label in y_test.round()]\n",
    "decoded_y_pred = [byte_to_mbti(label) for label in y_pred.round()]\n",
    "\n",
    "matrix = confusion_matrix(decoded_y_true, decoded_y_pred, labels=type_labels)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plot_confusion_matrix(matrix, classes=type_labels, normalize=True,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "log_file = open('results.log', 'a+')\n",
    "\n",
    "stat = \"=================================\\n\" + \\\n",
    "str(now.month) + \"/\" + str(now.day) + \"/\" + str(now.year) + \" \" + \\\n",
    "str(now.hour) + \":\" + str(now.minute) + \":\" + str(now.second) + \"\\n\" + \\\n",
    "\"\\nSEED:\\t\" + str(SEED) +\" \\n\" + \\\n",
    "\"Layer1:\\t\" + str(LAYER1_PARAMS) +\" \\n\" + \\\n",
    "\"Layer2:\\t\" + str(LAYER2_PARAMS) +\" \\n\" + \\\n",
    "\"Layer3:\\t\" + str(LAYER3_PARAMS) +\" \\n\" + \\\n",
    "\"Generalizers:\\t\" + \"\\n\" + \\\n",
    "\"Compilation:\\t\" + str(COMPILATION_PARAMS) +\" \\n\" + \\\n",
    "\"Training: \" + \"EPOCHS \" + str(EPOCHS) + \" | \" + \"BATCH SIZE \" + str(BATCH_SIZE) + \"\\n\" + \\\n",
    "\"\\tRESULTS:\\t\" + \"LOSS:\" + str(results[0]) +  \" | \"+\"ACCURACY:\" + (str(results[1])) + \"\\n\" + \\\n",
    "\"\\n\"\n",
    "\n",
    "print(stat)\n",
    "log_file.write(stat)\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = build_model()\n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(x_partial_train, y_partial_train, epochs = 40, batch_size = 1024, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "train_loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "train_acc = history_dict['acc']\n",
    "val_acc   = history_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(history_dict['acc']) + 1)\n",
    "\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs, train_acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#K-Fold Validation\n",
    "k = 4\n",
    "\n",
    "# // is floor div operator\n",
    "num_val_samples = len(x_train) // k\n",
    "\n",
    "k_val_loss = []\n",
    "k_val_acc = []\n",
    "\n",
    "for num_epochs in range(1, 20):\n",
    "    print(\"Epoch:\",num_epochs)\n",
    "    loss = []\n",
    "    acc = []\n",
    "    for i in range(k):\n",
    "        val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "        partial_train_data = np.concatenate(\n",
    "            [x_train[:i * num_val_samples],\n",
    "             x_train[(i + 1) * num_val_samples:]],\n",
    "            axis=0)\n",
    "        partial_train_targets = np.concatenate(\n",
    "            [y_train[:i * num_val_samples],\n",
    "             y_train[(i + 1) * num_val_samples:]],\n",
    "            axis=0)\n",
    "\n",
    "        model = build_model()\n",
    "        with tf.device('/gpu:0'):\n",
    "            model.fit(partial_train_data, partial_train_targets,\n",
    "                epochs=num_epochs, batch_size=128,verbose = 0)\n",
    "\n",
    "            val_loss, val_acc = model.evaluate(val_data, val_targets, verbose = 0)\n",
    "\n",
    "        loss.append(val_loss)\n",
    "        acc.append(val_acc)\n",
    "        \n",
    "        del model\n",
    "        \n",
    "    k_val_loss.append(np.mean(loss))\n",
    "    k_val_acc.append(np.mean(acc))\n",
    "    print(str(k_val_loss[num_epochs - 1]), str(k_val_acc[num_epochs - 1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, 21)\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs, k_val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "plt.plot(epochs, k_val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "URE18_HOME",
   "language": "python",
   "name": "ure18_home"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
